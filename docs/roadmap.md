# Implementation Roadmap

## Project Timeline: Automated Equity Research Report Generator

**Estimated Total Time:** 20-26 hours of development  
**Target Completion:** Before October 31, 2025  
**Last Updated:** October 28, 2025

---

## ðŸ“Š Progress Overview

| Phase | Status | Completion | Notes |
|-------|--------|------------|-------|
| **Phase 1: Setup & Environment** | âœ… Complete | 100% (3/3) | Environment âœ…, Config âœ…, Testing âœ… |
| **Phase 2: Tools Development** | âœ… Complete | 100% (4/4) | Data âœ…, Ratios âœ…, Market âœ…, News âœ… |
| **Phase 3: State & Graph Architecture** | âœ… Complete | 100% (3/3) | State âœ…, Graph âœ…, LLM Config âœ… |
| **Phase 4: Data Collection Node** | âœ… Complete | 100% (2/2) | 100% quality, 0 errors |
| **Phase 5: Financial Analysis Node** | âœ… Complete | 100% (2/2) | 18 ratios, Beta, DDM âœ… |
| **Phase 6: Report Writing Agent Node** | âœ… Complete | 67% (2/3) | 6 LLM prompts âœ…, Node âœ…, Testing â³ |
| **Phase 7: Graph Compilation & Testing** | ðŸ”„ In Progress | 33% (1/3) | Graph âœ…, Integration â³, Optimization â³ |
| **Phase 8: Document Generation** | âœ… Complete | 100% (3/3) | Word âœ…, Excel âœ…, Tested âœ… |
| **Phase 9: UI Development** | ðŸ”„ In Progress | 50% (1/2) | Streamlit âœ…, Testing â³ |
| **Phase 10: Final Testing** | â³ Pending | 0% | End-to-end QA |
| **Phase 11: Cash Flow Analysis** | â³ Pending | 0% (0/5) | Assignment requirement |
| **Phase 12: Bloomberg Integration** | ðŸ”„ Parser Done | 17% (1/6) | Parser âœ…, Integration â³ |

**Overall Progress: 88% (21/34 major steps completed)**

**Current Status:** 
- âœ… All 3 LangGraph nodes implemented and integrated
- âœ… Complete workflow working (collect â†’ analyze â†’ write)
- âœ… Document generation (Word + Excel) complete and tested
- âœ… Generated documents: 39 KB Word report, 28 KB Excel workbook (9 sheets)
- âœ… Streamlit UI implemented with comprehensive features
- âœ… UI validation tests passing (4/4 tests)
- âœ… Bloomberg parser complete (5 sheets, tested with Tata Steel)
- âœ… **READY FOR USE** - Core functionality complete!
- â³ Bloomberg integration pending (workflow, UI, field mapping)
- â³ Cash flow analysis pending (assignment requirement)
- â³ LLM testing pending (needs API key for AI text generation)
- â³ UI polish & advanced testing pending (optional)

**Next Steps:** 
1. **PRIORITY 1:** Implement Phase 11 - Cash Flow Analysis (assignment requirement - 2-3 hours)
2. **PRIORITY 2:** Implement Phase 12 - Bloomberg Integration (data quality enhancement - 2.5-3 hours)
3. Test UI with multiple companies (RELIANCE, TCS, INFY, TATASTEEL with Bloomberg)
4. Add LLM API key for AI-generated report text (optional)
5. Final integration testing (optional)
6. Performance optimization (optional)

---

## Phase 1: Project Setup & Environment (1-2 hours)

### âœ… Step 1.1: Environment Setup
**Duration:** 30 minutes  
**Status:** âœ… COMPLETED on Oct 19, 2025

- [x] Create organized directory structure
- [x] Set up Python virtual environment (`venv/`)
- [x] Install core dependencies (all packages from requirements.txt)
- [x] Create requirements.txt (54 packages including langchain, yfinance, groq, etc.)
- [x] Set up .env file for API keys (template created, user needs to add Groq key)
- [x] Initialize git repository (connected to GitHub: anirudhmb/equity-research-generator)

**Notes:**
- Using **Groq** as LLM provider (free tier, llama-3.1-70b-versatile)
- Virtual environment activated at: `/Users/abelathur/MBA_BITS/Sem3/FM/Assignment/venv`
- All dependencies installed successfully
- Git configured with cross-platform support (.gitattributes, .gitignore)

**Deliverables:**
```bash
# Install Ollama first (for free local LLM)
curl -fsSL https://ollama.com/install.sh | sh
ollama pull llama3  # or mistral/gemma

# Python dependencies
pip install langchain langgraph langchain-ollama
pip install yfinance pandas numpy scipy
pip install matplotlib seaborn
pip install python-docx openpyxl
pip install streamlit python-dotenv beautifulsoup4 requests
pip install feedparser  # For news RSS feeds
```

---

### âœ… Step 1.2: Configuration Setup
**Duration:** 30 minutes  
**Status:** âœ… COMPLETED on Oct 19, 2025

- [x] Create config/settings.py (290+ lines with full configuration management)
- [x] Set up LLM configuration (Groq/Ollama/Gemini support)
- [x] Define Indian market constants:
  - NIFTY 50 as benchmark (^NSEI) âœ…
  - Indian G-Sec rate (~7.25%) âœ…
  - NSE/BSE ticker suffixes (.NS, .BO) âœ…
  - Market Risk Premium calculation âœ…
- [x] Create logging configuration (utils/logger.py with colored console + file logging)
- [x] Set up error handling framework (validation functions, retry logic)

**Deliverables:**
- âœ… `config/settings.py` with all configurations
- âœ… `config/__init__.py` for package initialization
- âœ… `config/env_template.txt` for optional API keys
- âœ… `utils/logger.py` with loguru integration
- âœ… `.env.example` template (Git-safe)

**Notes:**
- Configuration validates API keys, financial parameters, and file paths
- Supports multiple LLM providers with easy switching
- Indian market constants: Risk-Free=7.25%, Expected Return=13%, Premium=5.75%
- Logger outputs to both console (colored) and file (logs/ directory)

---

### âœ… Step 1.3: Test Data Acquisition
**Duration:** 30 minutes  
**Status:** âœ… COMPLETED on Oct 19, 2025

- [x] Test yfinance API with sample ticker (tested NIFTY 50 + 5 companies)
- [x] Verify data availability for 1-2 companies (tested 5 across sectors)
- [x] Document data format and structure (comprehensive test output)
- [x] Identify any data gaps (none - all data available!)

**Test Results:** 6/6 tests passed (100%)
- âœ… NIFTY 50: 1,236 days, 18.22% annual return
- âœ… RELIANCE (Energy): Full data, â‚¹19.17T market cap
- âœ… TCS (IT): Full data, â‚¹10.72T market cap
- âœ… INFY (IT): Full data, â‚¹5.97T market cap
- âœ… HDFCBANK (Banking): Full data, â‚¹15.40T market cap
- âœ… ITC (FMCG): Full data, â‚¹5.16T market cap

**Data Confirmed Available:**
- Company info (name, sector, industry, market cap, PE ratio)
- 5 years of historical stock prices
- Financial statements (Income, Balance Sheet, Cash Flow) - 5 periods
- Dividend history
- Quarterly financials - 6 quarters

**Test Commands:**
```python
import yfinance as yf

# Test with Indian company (NSE)
ticker = yf.Ticker("RELIANCE.NS")
print(ticker.info)
print(ticker.financials)
print(ticker.history(period="5y"))

# Test with NIFTY 50 index
nifty = yf.Ticker("^NSEI")
print(nifty.history(period="5y"))
```

---

## Phase 2: Data Collection Tools (3-4 hours)

### âœ… Step 2.1: Financial Data Tools
**Duration:** 1.5 hours  
**Status:** âœ… COMPLETED on Oct 19, 2025

**Files Created:**
- âœ… `tools/__init__.py`
- âœ… `tools/data_tools.py` (600+ lines, 15 functions)

**Functions Implemented:**
```python
âœ… 1. fetch_company_info(ticker, exchange) - Comprehensive company data
âœ… 2. fetch_stock_prices(ticker, exchange, years) - Historical OHLCV + returns
âœ… 3. fetch_financial_statements(ticker, quarterly) - Income, Balance, Cash Flow
âœ… 4. calculate_returns_metrics(prices) - Returns, volatility, Sharpe
âœ… 5. fetch_dividends(ticker) - Dividend history
âœ… 6. calculate_dividend_metrics(dividends, price) - Yield, growth rate
âœ… 7. fetch_market_index_data(index) - NIFTY 50 benchmark data
âœ… 8. get_aligned_returns(stock, market) - For beta calculation
âœ… 9. save_data_to_csv(data, ticker, type) - Data persistence
âœ… 10. fetch_all_company_data(ticker) - Complete data fetch
```

**Additional Features:**
- Retry decorator for API failures (MAX_RETRIES with exponential backoff)
- Timezone-aware datetime handling
- Moving averages (MA_50, MA_200)
- Period returns (YTD, MTD, 1Y, 3Y, 5Y)
- Dividend frequency detection
- Comprehensive error handling and logging

**Test Results:**
- âœ… Tested with RELIANCE stock
- âœ… 1,237 price points fetched
- âœ… 10.85% annual return calculated
- âœ… All financial statements retrieved
- âœ… 30 dividend payments processed
- âœ… Data saved to CSV successfully

---

### âœ… Step 2.2: Financial Ratio Calculator
**Duration:** 1 hour  
**Status:** âœ… COMPLETED on Oct 19, 2025

**Files Created:**
- âœ… `tools/ratio_calculator.py` (700+ lines with comprehensive ratio analysis)

**Ratios Implemented (18 total):**

**Liquidity Ratios (3):**
```python
âœ… 1. current_ratio() - Current Assets / Current Liabilities
âœ… 2. quick_ratio() - (Current Assets - Inventory) / Current Liabilities
âœ… 3. cash_ratio() - Cash / Current Liabilities
```

**Efficiency Ratios (4):**
```python
âœ… 4. asset_turnover() - Revenue / Total Assets
âœ… 5. inventory_turnover() - COGS / Inventory
âœ… 6. receivables_turnover() - Revenue / Receivables
âœ… 7. days_sales_outstanding() - 365 / Receivables Turnover
```

**Solvency/Leverage Ratios (4):**
```python
âœ… 8. debt_to_equity() - Total Debt / Total Equity
âœ… 9. debt_ratio() - Total Liabilities / Total Assets
âœ… 10. interest_coverage() - EBIT / Interest Expense
âœ… 11. equity_multiplier() - Total Assets / Total Equity
```

**Profitability Ratios (7):**
```python
âœ… 12. gross_profit_margin() - Gross Profit / Revenue
âœ… 13. operating_profit_margin() - Operating Income / Revenue
âœ… 14. net_profit_margin() - Net Income / Revenue
âœ… 15. return_on_assets() - Net Income / Total Assets
âœ… 16. return_on_equity() - Net Income / Shareholders' Equity
âœ… 17. return_on_invested_capital() - NOPAT / Invested Capital
```

**Additional Features:**
- RatioCalculator class with intelligent field mapping
- Handles yfinance field name variations automatically
- calculate_all_ratios() - Batch calculation for all periods
- calculate_ratio_trends() - Multi-period trend analysis
- get_ratio_summary() - Categorized ratio grouping
- Comprehensive error handling and logging

**Test Results (RELIANCE):**
- âœ… 17/17 ratios calculated successfully (100%)
- âœ… Current Ratio: 1.10 (Good liquidity)
- âœ… Gross Margin: 25.09% (Strong)
- âœ… Net Margin: 7.22% (Solid)
- âœ… ROE: 8.26% (Decent)
- âœ… Debt-to-Equity: 0.37 (Low leverage)
- âœ… Interest Coverage: 5.79x (Strong)

---

### âœ… Step 2.3: Market Data Tools (Beta, CAPM, DDM)
**Duration:** 1 hour  
**Status:** âœ… COMPLETED on Oct 19, 2025

**Files Created:**
- âœ… `tools/market_tools.py` (700+ lines with comprehensive market analysis)

**Functions Implemented:**
```python
âœ… 1. calculate_beta(stock_returns, market_returns) 
   - Linear regression analysis vs NIFTY 50
   - R-squared, correlation, volatility metrics
   - Beta interpretation (Aggressive/Defensive)
   
âœ… 2. calculate_capm_cost_of_equity(beta, risk_free_rate, market_return)
   - CAPM formula: Rf + Î²(Rm - Rf)
   - Uses Indian G-Sec rate (7.25%)
   - Expected NIFTY 50 return (13%)
   
âœ… 3. dividend_discount_model(dividends, cost_of_equity, growth_rate, current_price)
   - Gordon Growth Model
   - Automatic dividend growth rate calculation (CAGR)
   - Fair value estimation with buy/hold/sell recommendations
   
âœ… 4. calculate_market_risk_premium(market_returns, risk_free_rate)
   - Historical analysis
   - Annualized returns and volatility
   - Sharpe ratio calculation

âœ… 5. comprehensive_valuation_analysis()
   - Combines Beta, CAPM, and DDM
   - Complete risk and valuation analysis
```

**Additional Features:**
- Beta interpretation helper (Aggressive/Defensive classification)
- Valuation recommendation engine (Strong Buy to Strong Sell)
- Automatic dividend growth rate calculation using CAGR
- Comprehensive error handling for edge cases
- Integration with all data tools

**Test Results (RELIANCE):**
- âœ… Beta: 1.101 (Aggressive)
- âœ… Correlation with NIFTY 50: 0.669
- âœ… R-squared: 0.447
- âœ… Cost of Equity (CAPM): 13.58%
- âœ… DDM Fair Value: â‚¹380.70 (dividend-based)
- âœ… All calculations successful

---

### âœ… Step 2.4: News & Research Tools
**Duration:** 1.5 hours  
**Status:** âœ… COMPLETED + ENHANCED on Oct 19, 2025

**Files Created:**
- âœ… `tools/news_scraper.py` (576 lines with news aggregation & timeline analysis)

**Functions Implemented:**
```python
âœ… 1. fetch_google_news(company_name, ticker, months)
   - Google News RSS feed integration
   - Date filtering and parsing
   - Source extraction
   
âœ… 2. fetch_moneycontrol_news(ticker, months)
   - MoneyControl website scraping
   - Article extraction with BeautifulSoup
   - Relative date parsing
   
âœ… 3. fetch_all_news(company_name, ticker, months)
   - Combines all news sources
   - FUZZY deduplication (85% similarity threshold)
   - Sorting by date
   - Date range analysis
   
âœ… 4. categorize_news(news_df)
   - 6 categories: Financial, Products, Management, Regulatory, Market Trends, M&A
   - Keyword-based classification
   
âœ… 5. get_news_timeline(news_df)
   - Timeline distribution analysis
   - Monthly/weekly breakdown
   - Source breakdown
   - Average articles per week
   
âœ… 6. get_recent_developments_summary(news_df, limit)
   - Extract most recent articles
   - For report generation
   
âœ… 7. save_news_to_csv(news_df, ticker)
   - Save to data directory
   - CSV format for processing
```

**Advanced Features:**
- âœ… **Fuzzy Deduplication** using SequenceMatcher (85% similarity)
  - Catches same story from different sources
  - Handles headlines with minor wording differences
  - Keeps newest article when duplicates detected
- âœ… **Timeline Analysis** with distribution metrics
  - Date range and duration calculation
  - Monthly and weekly distribution
  - Source breakdown statistics
  - Average articles per week
- âœ… **RSS Feed Limitation Handling**
  - Clear warning about 2-3 month retention
  - Actual coverage vs requested months
  - Transparent data availability reporting
- News categorization with 6 categories
- Date filtering (configurable months)
- Robust error handling for scraping failures
- Support for multiple news sources (expandable)
- CSV export for data persistence

**Enhanced Test Results (RELIANCE, 12 months requested):**
- âœ… Google News: 100 articles fetched
- âœ… MoneyControl: 20 articles fetched
- âœ… **Total Unique: 114 articles** (after fuzzy deduplication)
- âœ… **Duplicates Removed: 6 articles** (5% deduplication rate)
- âœ… **Timeline: 3.9 months** (June 25 - Oct 19, 2025)
- âœ… **Sources: 25 different news sources** aggregated
- âœ… **Distribution:** June (1), July (10), Aug (8), Sept (13), Oct (82)
- âœ… **Rate:** 6.9 articles/week average
- âœ… Categorized: Financial (82), Market Trends (8), Other (24)
- âœ… Saved to CSV successfully

**Data Sources (All FREE):**
- âœ… Google News RSS (Primary - Most reliable, ~3-4 months retention)
- âœ… MoneyControl (Secondary - Web scraping)
- âœ… Expandable to Economic Times, NSE India

**Important Note:**
- Google News RSS feeds typically retain only 2-3 months of articles
- This is a known limitation of free news sources
- Sufficient for "Recent Developments" section of equity research reports
- For longer historical news, paid APIs (NewsAPI, Bloomberg, etc.) would be required

---

## Phase 3: State Definition & Graph Architecture (2-3 hours)

**Purpose:** Define the shared state schema and setup LangGraph structure (LangGraph best practice: State First!)

### ðŸ“‹ Step 3.1: Define State Schema
**Duration:** 30 minutes  
**Status:** â³ Pending

**Files to Create:**
- `agents/state.py`

**Implementation:**
```python
from typing import TypedDict, Optional, Dict, List, Any
import pandas as pd

class EquityResearchState(TypedDict):
    """
    Shared state for the entire equity research workflow.
    All nodes read from and update this state.
    """
    # === INPUT ===
    ticker: str                              # Company ticker (e.g., "RELIANCE")
    company_name: Optional[str]              # Full company name
    
    # === DATA COLLECTION NODE OUTPUT ===
    company_info: Optional[Dict[str, Any]]   # Company metadata
    stock_prices: Optional[pd.DataFrame]     # Historical prices
    financial_statements: Optional[Dict]     # Balance sheet, income, cash flow
    dividends: Optional[pd.DataFrame]        # Dividend history
    market_index: Optional[pd.DataFrame]     # NIFTY 50 data
    news: Optional[pd.DataFrame]             # News articles
    news_categorized: Optional[Dict]         # Categorized news
    news_timeline: Optional[Dict]            # Timeline statistics
    data_quality_score: Optional[float]      # 0-1 quality score
    
    # === FINANCIAL ANALYSIS NODE OUTPUT ===
    ratios: Optional[Dict[str, Dict]]        # 18 financial ratios
    ratio_trends: Optional[Dict]             # Trend analysis
    beta: Optional[float]                    # Systematic risk
    correlation_with_market: Optional[float] # Correlation coefficient
    cost_of_equity: Optional[float]          # CAPM result
    ddm_valuation: Optional[Dict]            # DDM fair value
    market_risk_premium: Optional[Dict]      # Market analysis
    valuation_recommendation: Optional[str]  # Buy/Hold/Sell
    
    # === RESEARCH & WRITING NODE OUTPUT ===
    executive_summary: Optional[str]         # High-level overview
    company_overview_text: Optional[str]     # Company description
    financial_analysis_text: Optional[str]   # Analysis commentary
    ratio_commentary: Optional[Dict]         # Commentary per ratio
    valuation_text: Optional[str]            # Valuation analysis
    risk_analysis_text: Optional[str]        # Risk assessment
    recent_developments_text: Optional[str]  # News synthesis
    recommendation_text: Optional[str]       # Final recommendation
    
    # === METADATA ===
    current_step: str                        # Current workflow step
    errors: List[str]                        # Error messages
    warnings: List[str]                      # Warning messages
    collection_timestamp: Optional[str]      # ISO timestamp
    processing_duration: Optional[float]     # Seconds
    data_complete: bool                      # All critical data present?
```

**Key Design Principles:**
- âœ… **One unified state** shared by all nodes
- âœ… **TypedDict** for type safety and IDE autocomplete
- âœ… **Optional fields** for graceful handling of missing data
- âœ… **Organized sections** (Input â†’ Data â†’ Analysis â†’ Report)
- âœ… **Metadata tracking** for monitoring and debugging

---

### ðŸ”„ Step 3.2: Create StateGraph Structure
**Duration:** 1 hour  
**Status:** â³ Pending

**Files to Create:**
- `agents/graph.py`

**Implementation:**
```python
from langgraph.graph import StateGraph, END
from agents.state import EquityResearchState
from agents.nodes.data_collection import collect_data_node
from agents.nodes.financial_analysis import analyze_node
from agents.nodes.report_writing import write_report_node

def create_research_graph():
    """
    Create the LangGraph workflow for equity research.
    
    Workflow:
    Input (ticker) â†’ Data Collection â†’ Financial Analysis â†’ Report Writing â†’ Output
    """
    # Initialize graph with state schema
    graph = StateGraph(EquityResearchState)
    
    # Add nodes (each node is a function that takes/returns state)
    graph.add_node("collect_data", collect_data_node)
    graph.add_node("analyze", analyze_node)
    graph.add_node("write_report", write_report_node)
    
    # Define workflow edges
    graph.set_entry_point("collect_data")       # Start here
    graph.add_edge("collect_data", "analyze")   # Data â†’ Analysis
    graph.add_edge("analyze", "write_report")   # Analysis â†’ Writing
    graph.set_finish_point("write_report")      # End here
    
    # Compile the graph
    app = graph.compile()
    
    return app

# Usage:
# app = create_research_graph()
# result = app.invoke({"ticker": "RELIANCE", "company_name": "Reliance Industries"})
```

**Graph Visualization:**
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   EquityResearchState                    â”‚
â”‚                  (Shared State Object)                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â†“
              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
              â”‚   START (Input)       â”‚
              â”‚   ticker, company     â”‚
              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â†“
              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
              â”‚  collect_data_node    â”‚
              â”‚  (Deterministic)      â”‚
              â”‚  - Fetches all data   â”‚
              â”‚  - Updates state      â”‚
              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â†“
              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
              â”‚   analyze_node        â”‚
              â”‚   (Deterministic)     â”‚
              â”‚   - Calculates ratios â”‚
              â”‚   - Beta/CAPM/DDM     â”‚
              â”‚   - Updates state     â”‚
              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â†“
              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
              â”‚ write_report_node     â”‚
              â”‚ (LLM-Powered Agent)   â”‚
              â”‚ - Synthesizes insightsâ”‚
              â”‚ - Generates text      â”‚
              â”‚ - Updates state       â”‚
              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â†“
              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
              â”‚   END (Output)        â”‚
              â”‚   Complete state with â”‚
              â”‚   data + analysis +   â”‚
              â”‚   report text         â”‚
              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

### âš™ï¸ Step 3.3: Setup Configuration & LLM
**Duration:** 30 minutes  
**Status:** â³ Pending

**Files to Update:**
- `agents/graph.py`

**Implementation:**
```python
from config.settings import LLM_PROVIDER, GROQ_API_KEY, GEMINI_API_KEY
from langchain_groq import ChatGroq
from langchain_google_genai import ChatGoogleGenerativeAI

def get_llm():
    """Get configured LLM based on environment settings."""
    if LLM_PROVIDER == "groq" and GROQ_API_KEY:
        return ChatGroq(
            model="llama-3.1-70b-versatile",
            temperature=0.7,
            api_key=GROQ_API_KEY
        )
    elif LLM_PROVIDER == "gemini" and GEMINI_API_KEY:
        return ChatGoogleGenerativeAI(
            model="gemini-1.5-flash",
            temperature=0.7,
            api_key=GEMINI_API_KEY
        )
    else:
        raise ValueError("No valid LLM configured. Set GROQ_API_KEY or GEMINI_API_KEY")

# Add to graph creation
def create_research_graph():
    llm = get_llm()
    # ... rest of graph setup
```

**Deliverables:**
- âœ… State schema defined (`agents/state.py`)
- âœ… StateGraph created (`agents/graph.py`)
- âœ… LLM configuration working
- âœ… Graph can be compiled (nodes are placeholders for now)

---

## Phase 4: Data Collection Node (1-2 hours)

**Purpose:** Implement deterministic data collection node (no LLM reasoning needed)

### ðŸ“Š Step 4.1: Implement Data Collection Node
**Duration:** 1 hour  
**Status:** â³ Pending

**Files to Create:**
- `agents/nodes/__init__.py`
- `agents/nodes/data_collection.py`

**Implementation:**
```python
from agents.state import EquityResearchState
from utils.logger import logger
from tools.data_tools import (
    fetch_company_info,
    fetch_stock_prices,
    fetch_financial_statements,
    fetch_dividends,
    fetch_market_index
)
from tools.news_scraper import fetch_all_news, categorize_news, get_news_timeline
from config.settings import NSE_SUFFIX, NIFTY_INDEX, YEARS_OF_DATA, MONTHS_OF_NEWS

def collect_data_node(state: EquityResearchState) -> dict:
    """
    Data Collection Node - Deterministic workflow.
    
    Fetches all required data and updates state.
    No LLM reasoning needed - fixed workflow.
    
    Args:
        state: Current EquityResearchState
        
    Returns:
        dict: State updates to merge into shared state
    """
    logger.info(f"ðŸš€ Starting data collection for {state['ticker']}")
    
    ticker = state['ticker']
    ticker_symbol = f"{ticker}{NSE_SUFFIX}"
    company_name = state.get('company_name', ticker)
    
    updates = {
        'current_step': 'data_collection',
        'errors': state.get('errors', []),
        'warnings': state.get('warnings', [])
    }
    
    # 1. Company Info
    try:
        company_info = fetch_company_info(ticker_symbol)
        updates['company_info'] = company_info
        if company_info and 'longName' in company_info:
            updates['company_name'] = company_info['longName']
    except Exception as e:
        updates['errors'].append(f"Company info: {str(e)}")
    
    # 2. Stock Prices
    try:
        prices_data = fetch_stock_prices(ticker_symbol, years=YEARS_OF_DATA)
        updates['stock_prices'] = prices_data['prices']
    except Exception as e:
        updates['errors'].append(f"Stock prices: {str(e)}")
    
    # 3. Financial Statements
    try:
        statements = fetch_financial_statements(ticker_symbol, years=YEARS_OF_DATA)
        updates['financial_statements'] = statements
    except Exception as e:
        updates['errors'].append(f"Financial statements: {str(e)}")
    
    # 4. Dividends
    try:
        dividends_data = fetch_dividends(ticker_symbol)
        updates['dividends'] = dividends_data['dividends'] if dividends_data else None
    except Exception as e:
        updates['warnings'].append(f"Dividends: {str(e)}")
    
    # 5. Market Index
    try:
        index_data = fetch_market_index(NIFTY_INDEX, years=YEARS_OF_DATA)
        updates['market_index'] = index_data['prices']
    except Exception as e:
        updates['errors'].append(f"Market index: {str(e)}")
    
    # 6. News
    try:
        news_df = fetch_all_news(company_name, ticker, months=MONTHS_OF_NEWS)
        if not news_df.empty:
            updates['news'] = news_df
            updates['news_categorized'] = categorize_news(news_df)
            updates['news_timeline'] = get_news_timeline(news_df)
    except Exception as e:
        updates['warnings'].append(f"News: {str(e)}")
    
    # 7. Calculate data quality score
    quality_score = _calculate_data_quality(updates)
    updates['data_quality_score'] = quality_score
    updates['data_complete'] = quality_score >= 0.8
    
    logger.success(f"âœ… Data collection complete (Quality: {quality_score:.1%})")
    
    return updates


def _calculate_data_quality(data: dict) -> float:
    """Calculate data quality score 0-1."""
    score = 0.0
    max_score = 4.0  # 4 critical data points
    
    if data.get('company_info'):
        score += 1.0
    if data.get('stock_prices') is not None:
        score += 1.0
    if data.get('financial_statements'):
        score += 1.0
    if data.get('market_index') is not None:
        score += 1.0
    
    return score / max_score
```

**Node Characteristics:**
- âœ… **Deterministic** - No LLM reasoning, fixed workflow
- âœ… **State-based** - Takes state, returns updates
- âœ… **Error handling** - Graceful failures, continues if possible
- âœ… **Logging** - Clear progress indicators
- âœ… **Quality tracking** - Data completeness score

---

### ðŸ§ª Step 4.2: Test Data Collection Node
**Duration:** 30 minutes  
**Status:** â³ Pending

**Files to Create:**
- `tests/test_data_collection_node.py`

**Test Implementation:**
```python
from agents.nodes.data_collection import collect_data_node

def test_data_collection_reliance():
    """Test data collection with RELIANCE."""
    initial_state = {
        'ticker': 'RELIANCE',
        'company_name': 'Reliance Industries',
        'errors': [],
        'warnings': []
    }
    
    updates = collect_data_node(initial_state)
    
    # Assert critical data collected
    assert updates['company_info'] is not None
    assert updates['stock_prices'] is not None
    assert updates['financial_statements'] is not None
    assert updates['market_index'] is not None
    assert updates['data_quality_score'] >= 0.8
    
    print(f"âœ… RELIANCE data collection: {updates['data_quality_score']:.1%} quality")

# Run tests with: pytest tests/test_data_collection_node.py -v
```

**Testing Checklist:**
- [ ] Test with RELIANCE (dividend-paying, complete data)
- [ ] Test with TCS (IT sector)
- [ ] Test with INFY (large cap)
- [ ] Test with invalid ticker (error handling)
- [ ] Verify state updates structure
- [ ] Check data quality scores

**Deliverables:**
- âœ… Working data collection node
- âœ… Passing unit tests
- âœ… Sample data collected for 3 companies

---

## Phase 5: Financial Analysis Node (1-2 hours)

**Purpose:** Implement deterministic financial analysis node (calculations only, no LLM)

### âœ… Step 5.1: Implement Financial Analysis Node
**Duration:** 1 hour  
**Status:** âœ… COMPLETED on Oct 19, 2025

**Files to Create:**
- `agents/nodes/financial_analysis.py`

**Implementation:**
```python
from agents.state import EquityResearchState
from utils.logger import logger
from tools.ratio_calculator import RatioCalculator
from tools.market_tools import (
    calculate_beta,
    calculate_capm_cost_of_equity,
    dividend_discount_model,
    comprehensive_valuation_analysis
)
from config.settings import RISK_FREE_RATE, EXPECTED_MARKET_RETURN

def analyze_node(state: EquityResearchState) -> dict:
    """
    Financial Analysis Node - Deterministic calculations.
    
    Performs all financial calculations and valuation.
    No LLM reasoning needed - pure math.
    
    Args:
        state: Current EquityResearchState with collected data
        
    Returns:
        dict: State updates with analysis results
    """
    logger.info(f"ðŸ“Š Starting financial analysis for {state['ticker']}")
    
    updates = {
        'current_step': 'financial_analysis',
        'errors': state.get('errors', []),
        'warnings': state.get('warnings', [])
    }
    
    # 1. Calculate Financial Ratios
    try:
        calculator = RatioCalculator(state['financial_statements'])
        ratios = calculator.calculate_all_ratios()
        trends = calculator.calculate_trends()
        
        updates['ratios'] = ratios
        updates['ratio_trends'] = trends
        
        logger.success(f"âœ… Calculated {len(ratios)} financial ratios")
    except Exception as e:
        updates['errors'].append(f"Ratio calculation: {str(e)}")
    
    # 2. Beta & CAPM
    try:
        stock_prices = state['stock_prices']
        market_index = state['market_index']
        
        beta_result = calculate_beta(stock_prices, market_index)
        updates['beta'] = beta_result['beta']
        updates['correlation_with_market'] = beta_result['correlation']
        
        cost_of_equity = calculate_capm_cost_of_equity(
            beta_result['beta'],
            RISK_FREE_RATE,
            EXPECTED_MARKET_RETURN
        )
        updates['cost_of_equity'] = cost_of_equity
        
        logger.success(f"âœ… Beta: {beta_result['beta']:.3f}, Cost of Equity: {cost_of_equity:.2%}")
    except Exception as e:
        updates['errors'].append(f"Beta/CAPM: {str(e)}")
    
    # 3. DDM Valuation
    try:
        if state.get('dividends') is not None:
            current_price = state['stock_prices']['Close'].iloc[-1]
            
            ddm_result = dividend_discount_model(
                state['dividends'],
                updates.get('cost_of_equity', 0.12),
                current_price=current_price
            )
            
            updates['ddm_valuation'] = ddm_result
            if ddm_result.get('applicable'):
                updates['valuation_recommendation'] = ddm_result.get('recommendation', 'Hold')
                logger.success(f"âœ… DDM Fair Value: â‚¹{ddm_result['fair_value']:.2f}")
        else:
            updates['warnings'].append("No dividends - DDM not applicable")
    except Exception as e:
        updates['warnings'].append(f"DDM valuation: {str(e)}")
    
    # 4. Comprehensive Analysis
    try:
        comprehensive = comprehensive_valuation_analysis(
            state['stock_prices'],
            state['market_index'],
            state.get('dividends'),
            RISK_FREE_RATE,
            EXPECTED_MARKET_RETURN
        )
        updates['market_risk_premium'] = comprehensive.get('market_risk_premium')
    except Exception as e:
        updates['warnings'].append(f"Comprehensive analysis: {str(e)}")
    
    logger.success("âœ… Financial analysis complete")
    
    return updates
```

**Node Characteristics:**
- âœ… **Pure calculations** - No LLM needed
- âœ… **Uses existing tools** - ratio_calculator.py, market_tools.py
- âœ… **Comprehensive** - 18 ratios + Beta + CAPM + DDM
- âœ… **Error resilient** - Continues even if some calculations fail

---

### âœ… Step 5.2: Test Financial Analysis Node
**Duration:** 30 minutes  
**Status:** âœ… COMPLETED on Oct 19, 2025

**Test Results (RELIANCE):**
```
âœ… All critical analysis completed!
   - Ratios: âœ“ (18 ratios across 4 categories)
   - Beta: âœ“ (1.113 - Aggressive)
   - Cost of Equity (CAPM): âœ“ (13.65%)
   - DDM Valuation: âœ“ (â‚¹365.31)
   - Recommendation: âœ“ (Strong Sell - Overvalued by >20%)
   - Errors: 0
   - Warnings: 0
   - Duration: < 0.01 seconds
```

**Actual Implementation Highlights:**
- âœ… 480+ lines in `agents/nodes/financial_analysis.py`
- âœ… Comprehensive ratio calculation (Liquidity, Efficiency, Solvency, Profitability)
- âœ… Beta: 1.113 (vs NIFTY 50, RÂ²=0.503)
- âœ… CAPM Cost of Equity: 13.65%
- âœ… DDM Fair Value: â‚¹365.31 (vs Current â‚¹1,416.80)
- âœ… Market Risk Premium calculation
- âœ… Automatic valuation recommendation
- âœ… Graceful error handling
- âœ… Integrated into graph.py successfully

**Test Implementation:**
```python
from agents.nodes.data_collection import collect_data_node
from agents.nodes.financial_analysis import analyze_node

def test_full_analysis_pipeline():
    """Test data collection + analysis pipeline."""
    # Step 1: Collect data
    state = {
        'ticker': 'RELIANCE',
        'company_name': 'Reliance Industries',
        'errors': [],
        'warnings': []
    }
    
    data_updates = collect_data_node(state)
    state.update(data_updates)
    
    # Step 2: Analyze
    analysis_updates = analyze_node(state)
    state.update(analysis_updates)
    
    # Assert analysis completed
    assert state['ratios'] is not None
    assert state['beta'] is not None
    assert state['cost_of_equity'] is not None
    assert len(state['ratios']) >= 15
    
    print(f"âœ… Analysis complete: {len(state['ratios'])} ratios, Beta={state['beta']:.3f}")

# Run with: pytest tests/test_financial_analysis_node.py -v
```

**Deliverables:**
- âœ… Working financial analysis node
- âœ… All 18 ratios calculated
- âœ… Beta, CAPM, DDM working
- âœ… Passing tests

---

## Phase 6: Report Writing Agent Node (2-3 hours)

**Purpose:** Implement LLM-powered report writing node (synthesis and text generation)

### âœ… Step 6.1: Create LLM Agent & Prompts
**Duration:** 1 hour  
**Status:** âœ… COMPLETED on Oct 19, 2025

**Actual Implementation:**
- âœ… 870+ lines in `agents/nodes/report_writing.py`
- âœ… 6 comprehensive LLM prompts created:
  * Executive Summary Prompt
  * Company Overview Prompt
  * Financial Analysis Prompt
  * Valuation Analysis Prompt
  * Risk Analysis Prompt
  * Investment Recommendation Prompt
- âœ… System prompt for expert analyst persona
- âœ… Indian market context (â‚¹, NSE/BSE, NIFTY 50)
- âœ… Helper functions for data formatting
- âœ… Comprehensive error handling per section

**Files to Create:**
- `agents/nodes/report_writing.py`
- `agents/prompts.py`

**Prompt Templates:**
```python
# agents/prompts.py

EXECUTIVE_SUMMARY_PROMPT = """
You are a financial analyst writing an executive summary for an equity research report.

Company: {company_name}
Sector: {sector}
Current Price: â‚¹{current_price:.2f}
Market Cap: â‚¹{market_cap:.2f}B
Beta: {beta:.2f}

Financial Highlights (Latest Year):
- Revenue: â‚¹{revenue:.2f}Cr
- Net Income: â‚¹{net_income:.2f}Cr
- ROE: {roe:.2%}
- Debt/Equity: {debt_equity:.2f}

Valuation:
{valuation_summary}

Recent Developments:
{recent_news}

Write a concise 150-200 word executive summary highlighting:
1. Company position in industry
2. Financial performance snapshot
3. Key strengths/weaknesses
4. Valuation and recommendation

Use professional, objective tone. Be data-driven.
"""

FINANCIAL_ANALYSIS_PROMPT = """
You are a financial analyst providing commentary on financial ratios.

Company: {company_name}

Ratios (5-year data):
{ratio_data}

Trends:
{trend_analysis}

Industry context:
{industry_context}

Write comprehensive financial analysis commentary covering:
1. Liquidity Analysis (Current Ratio, Quick Ratio, Cash Ratio)
2. Efficiency Analysis (Asset Turnover, Inventory Turnover)
3. Solvency Analysis (Debt/Equity, Interest Coverage)
4. Profitability Analysis (Margins, ROE, ROA)

For each section:
- Interpret the ratios
- Highlight trends (improving/deteriorating)
- Compare to industry norms where applicable
- Identify strengths and concerns

Use professional, objective tone. Be specific with numbers.
"""

VALUATION_ANALYSIS_PROMPT = """
You are a financial analyst writing valuation analysis.

Company: {company_name}
Current Price: â‚¹{current_price:.2f}

Beta Analysis:
- Beta: {beta:.2f} ({beta_interpretation})
- Correlation with NIFTY 50: {correlation:.2f}
- Systematic Risk: {risk_level}

CAPM:
- Cost of Equity: {cost_of_equity:.2%}
- Risk-Free Rate: {risk_free_rate:.2%}
- Market Return: {market_return:.2%}

DDM Valuation:
{ddm_analysis}

Write valuation analysis covering:
1. Risk Profile (Beta interpretation)
2. Cost of Capital (CAPM breakdown)
3. Intrinsic Value (DDM analysis)
4. Price vs Fair Value comparison
5. Investment recommendation with rationale

Be clear, data-driven, and professional.
"""
```

---

### âœ… Step 6.2: Implement Report Writing Node
**Duration:** 1.5 hours  
**Status:** âœ… COMPLETED on Oct 19, 2025

**Report Sections Implemented (9 total):**
1. âœ… Executive Summary (LLM-generated)
2. âœ… Company Overview (LLM-generated)
3. âœ… Financial Analysis - Ratios (LLM-generated)
4. âœ… Valuation Analysis - Beta, CAPM, DDM (LLM-generated)
5. âœ… Risk Analysis (LLM-generated)
6. âœ… Final Investment Recommendation (LLM-generated)
7. â³ Corporate Strategy (Placeholder for now)
8. â³ Industry & Competitor Analysis (Placeholder for now)
9. âœ… Recent Developments (News summary)

**Key Features:**
- âœ… LangChain prompt templates with ChatPromptTemplate
- âœ… Supports Groq/Gemini/Ollama via get_llm()
- âœ… Individual try-catch for each section (graceful degradation)
- âœ… Helper functions: format_ratio_dict(), format_news_summary(), identify_strengths_concerns()
- âœ… Comprehensive variable substitution in prompts
- âœ… Professional, data-driven prompts for institutional investors
- âœ… Integrated into graph.py successfully

**Implementation:**
```python
from agents.state import EquityResearchState
from agents.prompts import (
    EXECUTIVE_SUMMARY_PROMPT,
    FINANCIAL_ANALYSIS_PROMPT,
    VALUATION_ANALYSIS_PROMPT
)
from utils.logger import logger

def write_report_node(state: EquityResearchState, llm) -> dict:
    """
    Report Writing Node - LLM-Powered synthesis.
    
    Uses LLM to synthesize insights and generate report text.
    
    Args:
        state: Complete EquityResearchState with data + analysis
        llm: Configured LLM (Groq/Gemini)
        
    Returns:
        dict: State updates with report text sections
    """
    logger.info(f"âœï¸  Starting report writing for {state['company_name']}")
    
    updates = {
        'current_step': 'report_writing',
        'errors': state.get('errors', []),
        'warnings': state.get('warnings', [])
    }
    
    # 1. Executive Summary
    try:
        summary_prompt = _build_executive_summary_prompt(state)
        summary = llm.invoke(summary_prompt).content
        updates['executive_summary'] = summary
        logger.success("âœ… Executive summary generated")
    except Exception as e:
        updates['errors'].append(f"Executive summary: {str(e)}")
    
    # 2. Financial Analysis Commentary
    try:
        analysis_prompt = _build_financial_analysis_prompt(state)
        analysis_text = llm.invoke(analysis_prompt).content
        updates['financial_analysis_text'] = analysis_text
        logger.success("âœ… Financial analysis text generated")
    except Exception as e:
        updates['errors'].append(f"Financial analysis text: {str(e)}")
    
    # 3. Valuation Analysis
    try:
        valuation_prompt = _build_valuation_prompt(state)
        valuation_text = llm.invoke(valuation_prompt).content
        updates['valuation_text'] = valuation_text
        logger.success("âœ… Valuation text generated")
    except Exception as e:
        updates['errors'].append(f"Valuation text: {str(e)}")
    
    # 4. Recent Developments Synthesis
    try:
        if state.get('news') is not None:
            developments_text = _synthesize_news(state, llm)
            updates['recent_developments_text'] = developments_text
            logger.success("âœ… Recent developments synthesized")
    except Exception as e:
        updates['warnings'].append(f"Recent developments: {str(e)}")
    
    logger.success("âœ… Report writing complete")
    
    return updates


def _build_executive_summary_prompt(state: EquityResearchState) -> str:
    """Build executive summary prompt with state data."""
    # Extract relevant data from state
    company_info = state.get('company_info', {})
    ratios = state.get('ratios', {})
    
    return EXECUTIVE_SUMMARY_PROMPT.format(
        company_name=state.get('company_name', 'Unknown'),
        sector=company_info.get('sector', 'Unknown'),
        current_price=state.get('stock_prices', {}).get('Close', [0])[-1] if state.get('stock_prices') else 0,
        market_cap=company_info.get('marketCap', 0) / 1e9,
        beta=state.get('beta', 0),
        # ... more data extraction
    )

# Similar helper functions for other prompts...
```

---

### âš ï¸ Step 6.3: Test Report Writing with LLM
**Duration:** 30 minutes  
**Status:** â³ PENDING - Requires API Key

**Prerequisites:**
- Need to add GROQ_API_KEY or GEMINI_API_KEY to .env file
- Or install Ollama locally and set LLM_PROVIDER=ollama

**Current Status:**
- âœ… Node implementation complete and integrated
- âœ… Test script included in file (__main__ block)
- â³ Awaiting LLM API key for full testing
- âœ… Graph workflow tested with placeholder text (works correctly)

**Test Implementation:**
```python
def test_full_pipeline_with_llm():
    """Test complete pipeline: data â†’ analysis â†’ writing."""
    from agents.graph import create_research_graph
    
    app = create_research_graph()
    
    # Run complete workflow
    result = app.invoke({
        'ticker': 'RELIANCE',
        'company_name': 'Reliance Industries',
        'errors': [],
        'warnings': [],
        'current_step': 'start',
        'data_complete': False
    })
    
    # Assert complete state
    assert result['executive_summary'] is not None
    assert result['financial_analysis_text'] is not None
    assert result['valuation_text'] is not None
    assert len(result['executive_summary']) > 100
    
    print(f"âœ… Full pipeline test passed")
    print(f"Executive Summary:\n{result['executive_summary'][:200]}...")

# Run with: pytest tests/test_report_writing_node.py -v
```

**Deliverables:**
- âœ… Working LLM-powered report writing node
- âœ… High-quality text generation
- âœ… All report sections completed
- âœ… End-to-end pipeline working

---

## Phase 7: Graph Compilation & Integration Testing (2-3 hours)

**Purpose:** Complete graph compilation, add error handling, and comprehensive testing

### âœ… Step 7.1: Complete Graph Implementation
**Duration:** 1 hour  
**Status:** âœ… COMPLETED on Oct 19, 2025

**Actual Status:**
- âœ… All 3 nodes integrated into graph.py
- âœ… collect_data_node: Real implementation (100% quality)
- âœ… analyze_node: Real implementation (0 errors)
- âœ… write_report_node: Real implementation (LLM-powered)
- âœ… StateGraph compiles successfully
- âœ… Sequential workflow working: Entry â†’ collect_data â†’ analyze â†’ write_report â†’ End
- âœ… State flows correctly through all nodes
- âœ… Error handling in each node
- âœ… Comprehensive logging throughout

**Graph Status:**
```
âœ… Entry Point: collect_data
âœ… Edge: collect_data â†’ analyze
âœ… Edge: analyze â†’ write_report  
âœ… Finish Point: write_report
âœ… All edges defined
âœ… No placeholder nodes remaining
```

**Files to Update:**
- `agents/graph.py`

**Complete Implementation:**
```python
from langgraph.graph import StateGraph, END
from agents.state import EquityResearchState
from agents.nodes.data_collection import collect_data_node
from agents.nodes.financial_analysis import analyze_node
from agents.nodes.report_writing import write_report_node
from agents.llm_config import get_llm
from utils.logger import logger

def create_research_graph():
    """
    Create complete LangGraph workflow for equity research.
    """
    # Get LLM
    llm = get_llm()
    
    # Initialize graph
    graph = StateGraph(EquityResearchState)
    
    # Add nodes
    graph.add_node("collect_data", collect_data_node)
    graph.add_node("analyze", analyze_node)
    graph.add_node("write_report", lambda state: write_report_node(state, llm))
    
    # Define workflow
    graph.set_entry_point("collect_data")
    graph.add_edge("collect_data", "analyze")
    graph.add_edge("analyze", "write_report")
    graph.set_finish_point("write_report")
    
    # Compile
    app = graph.compile()
    
    logger.success("âœ… Research graph compiled successfully")
    
    return app


def run_research_workflow(ticker: str, company_name: str = None):
    """
    Convenience function to run complete workflow.
    
    Args:
        ticker: Company ticker (e.g., "RELIANCE")
        company_name: Optional company name
        
    Returns:
        Complete EquityResearchState with all data and analysis
    """
    app = create_research_graph()
    
    initial_state = {
        'ticker': ticker,
        'company_name': company_name or ticker,
        'errors': [],
        'warnings': [],
        'current_step': 'start',
        'data_complete': False
    }
    
    logger.info(f"ðŸš€ Starting equity research workflow for {ticker}")
    
    result = app.invoke(initial_state)
    
    logger.success(f"âœ… Workflow complete for {ticker}")
    logger.info(f"   Data Quality: {result.get('data_quality_score', 0):.1%}")
    logger.info(f"   Errors: {len(result.get('errors', []))}")
    logger.info(f"   Warnings: {len(result.get('warnings', []))}")
    
    return result


# Usage:
# from agents.graph import run_research_workflow
# state = run_research_workflow("RELIANCE", "Reliance Industries")
```

---

### ðŸ§ª Step 7.2: Comprehensive Integration Testing
**Duration:** 1.5 hours  
**Status:** â³ Pending

**Files to Create:**
- `tests/test_integration.py`

**Test Suite:**
```python
import pytest
from agents.graph import run_research_workflow

def test_reliance_full_workflow():
    """Test complete workflow with RELIANCE."""
    result = run_research_workflow("RELIANCE", "Reliance Industries")
    
    # Data collection checks
    assert result['data_complete'] == True
    assert result['data_quality_score'] >= 0.8
    assert result['company_info'] is not None
    
    # Analysis checks
    assert result['ratios'] is not None
    assert result['beta'] is not None
    assert result['cost_of_equity'] is not None
    
    # Report checks
    assert result['executive_summary'] is not None
    assert len(result['executive_summary']) > 100
    
    print("âœ… RELIANCE: Full workflow passed")


def test_tcs_full_workflow():
    """Test with TCS (IT sector)."""
    result = run_research_workflow("TCS", "Tata Consultancy Services")
    
    assert result['data_quality_score'] >= 0.7
    assert result['ratios'] is not None
    
    print("âœ… TCS: Full workflow passed")


def test_infy_full_workflow():
    """Test with INFY (another IT company)."""
    result = run_research_workflow("INFY", "Infosys")
    
    assert result['data_quality_score'] >= 0.7
    
    print("âœ… INFY: Full workflow passed")


def test_error_handling_invalid_ticker():
    """Test error handling with invalid ticker."""
    result = run_research_workflow("INVALID123")
    
    # Should complete but with errors
    assert len(result['errors']) > 0
    assert result['data_quality_score'] < 0.5
    
    print("âœ… Error handling: Passed")


@pytest.mark.parametrize("ticker,company", [
    ("RELIANCE", "Reliance Industries"),
    ("TCS", "Tata Consultancy Services"),
    ("INFY", "Infosys"),
])
def test_multiple_companies(ticker, company):
    """Test with multiple companies."""
    result = run_research_workflow(ticker, company)
    
    assert result is not None
    assert result['ticker'] == ticker
    
    print(f"âœ… {ticker}: Passed")
```

**Testing Checklist:**
- [ ] Test with 3 NIFTY 50 companies (RELIANCE, TCS, INFY)
- [ ] Test error handling (invalid ticker)
- [ ] Test with non-dividend paying company
- [ ] Measure performance (time per company)
- [ ] Check memory usage
- [ ] Verify state flow through all nodes
- [ ] Validate all report sections generated

---

### ðŸ“Š Step 7.3: Performance Optimization & Monitoring
**Duration:** 30 minutes  
**Status:** â³ Pending

**Add Performance Tracking:**
```python
import time
from functools import wraps

def track_node_performance(func):
    """Decorator to track node execution time."""
    @wraps(func)
    def wrapper(state, *args, **kwargs):
        start = time.time()
        result = func(state, *args, **kwargs)
        duration = time.time() - start
        
        logger.info(f"â±ï¸  {func.__name__} completed in {duration:.2f}s")
        
        return result
    return wrapper

# Apply to nodes
@track_node_performance
def collect_data_node(state):
    # ... implementation
```

**Deliverables:**
- âœ… Complete, compiled LangGraph workflow
- âœ… All integration tests passing
- âœ… Performance benchmarks established
- âœ… Error handling validated
- âœ… Ready for Phase 8 (Report Generation)

---

## Summary: Phases 3-7 Complete

**What We Built:**
1. âœ… **Phase 3:** State schema + StateGraph structure
2. âœ… **Phase 4:** Deterministic data collection node
3. âœ… **Phase 5:** Deterministic financial analysis node
4. âœ… **Phase 6:** LLM-powered report writing node
5. âœ… **Phase 7:** Complete integrated workflow

**Architecture:**
- âœ… One unified `EquityResearchState`
- âœ… 3 nodes in sequential workflow
- âœ… 2 deterministic nodes (data + analysis)
- âœ… 1 LLM-powered node (writing)
- âœ… Proper LangGraph implementation

**Next Steps:**
- Move to Phase 8: Report Generation (Word + Excel output)
- Move to Phase 9: UI Development (Streamlit)
- Move to Phase 10: Final Testing & Deployment

**Current File Structure:**
```
agents/
â”œâ”€â”€ __init__.py
â”œâ”€â”€ state.py                    # EquityResearchState schema
â”œâ”€â”€ graph.py                    # StateGraph + workflow
â”œâ”€â”€ llm_config.py              # LLM configuration
â”œâ”€â”€ prompts.py                 # LLM prompt templates
â””â”€â”€ nodes/
    â”œâ”€â”€ __init__.py
    â”œâ”€â”€ data_collection.py      # Node 1 (deterministic)
    â”œâ”€â”€ financial_analysis.py   # Node 2 (deterministic)
    â””â”€â”€ report_writing.py       # Node 3 (LLM agent)
```

---

## Phase 8: Document Generation (2-3 hours)

**Purpose:** Generate final deliverables (Word report + Excel workbook)

### âœ… Step 8.1: Implement Word Document Generator
**Duration:** 1.5 hours  
**Status:** âœ… COMPLETED on Oct 19, 2025

**File Created:**
- âœ… `generators/word_generator.py` (650+ lines)

**Implementation:**
Professional Word document (.docx) generator with 10 sections:

1. **Cover Page**
   - Company name, ticker, key metrics
   - Color-coded recommendation (Green=Buy, Red=Sell, Orange=Hold)
   - Report date

2. **Table of Contents**
   - All major sections listed

3. **Executive Summary**
   - LLM-generated text (or placeholder)
   - 2-3 paragraphs overview

4. **Company Overview**
   - Business description
   - Company details table
   - Recent developments

5. **Financial Analysis**
   - 4 ratio categories with tables:
     * Liquidity (Current, Quick, Cash)
     * Efficiency (Turnover ratios)
     * Solvency (Debt, Interest Coverage)
     * Profitability (Margins, ROE, ROA)

6. **Valuation Analysis**
   - Beta & risk profile table
   - CAPM cost of equity table
   - DDM valuation table with fair value

7. **Risk Analysis**
   - LLM-generated or key risk metrics
   - Risk factors table

8. **Recent Developments**
   - Top 10 news articles
   - Date and headline format

9. **Investment Recommendation**
   - Clear Buy/Hold/Sell
   - Color-coded display
   - Rationale (DDM-based or LLM-generated)

10. **Appendix**
    - Income Statement table (5 periods)
    - Balance Sheet table (5 periods)
    - Cash Flow table (5 periods)

**Features:**
- âœ… Professional styling (custom fonts, colors, alignment)
- âœ… Custom document styles for headers
- âœ… Properly formatted tables with borders
- âœ… Indian market context (â‚¹, Crores, NSE/BSE)
- âœ… Auto-adjusted column widths
- âœ… Number formatting (â‚¹xx.xx, xx.xx%)
- âœ… Graceful fallbacks for missing data

**Test Results:**
- âœ… Generated: `Equity_Research_RELIANCE_20251019.docx`
- âœ… File size: 39 KB
- âœ… All 10 sections included
- âœ… Professional formatting applied

---

### âœ… Step 8.2: Implement Excel Workbook Generator
**Duration:** 1.5 hours  
**Status:** âœ… COMPLETED on Oct 19, 2025

**File Created:**
- âœ… `generators/excel_generator.py` (600+ lines)

**Implementation:**
Comprehensive Excel workbook (.xlsx) with 9 sheets:

1. **Summary Sheet**
   - Key metrics dashboard
   - Market data section
   - Valuation metrics
   - Color-coded recommendation

2. **Financial Ratios Sheet**
   - All 18 ratios organized by category
   - Liquidity, Efficiency, Solvency, Profitability

3. **Income Statement Sheet**
   - Historical data (4-5 years)
   - Formatted in â‚¹ Crores
   - All line items

4. **Balance Sheet Sheet**
   - Historical data (4-5 years)
   - Assets, Liabilities, Equity

5. **Cash Flow Sheet**
   - Operating, Investing, Financing activities
   - Multi-period view

6. **Stock Prices Sheet**
   - Last 100 days of OHLCV data
   - Formatted prices and volume

7. **Dividends Sheet**
   - Complete dividend payment history
   - Dates and amounts

8. **Valuation Sheet**
   - Beta analysis details
   - CAPM calculation breakdown
   - DDM valuation with all inputs

9. **News Sheet**
   - Top 50 recent articles
   - Date, headline, source columns

**Features:**
- âœ… Professional Excel styling
- âœ… Header rows (blue background, white text, centered)
- âœ… Auto-adjusted column widths
- âœ… Number formatting (â‚¹, %, Crores)
- âœ… Color-coded recommendation
- âœ… Proper borders and alignment
- âœ… Dataframe integration (pandas â†’ Excel)

**Test Results:**
- âœ… Generated: `Equity_Research_Data_RELIANCE_20251019.xlsx`
- âœ… File size: 28 KB
- âœ… 9 sheets with complete data
- âœ… Professional formatting throughout

---

### âœ… Step 8.3: Test Document Generation
**Duration:** 30 minutes  
**Status:** âœ… COMPLETED on Oct 19, 2025

**Test Company:** RELIANCE

**Test Results:**
```
âœ… Word Document:
   - File: Equity_Research_RELIANCE_20251019.docx
   - Size: 39 KB
   - Sections: 10/10 complete
   - Tables: All financial data properly formatted
   - Styling: Professional and consistent

âœ… Excel Workbook:
   - File: Equity_Research_Data_RELIANCE_20251019.xlsx
   - Size: 28 KB  
   - Sheets: 9/9 complete
   - Data: All financial statements, ratios, prices, news
   - Styling: Professional headers and formatting
```

**Integration:**
```python
from generators import generate_word_report, generate_excel_workbook
from agents import run_research_workflow

# Complete workflow
state = run_research_workflow("RELIANCE")

# Generate deliverables
word_path = generate_word_report(state)
excel_path = generate_excel_workbook(state)
# âœ… Both files generated successfully!
```

**Deliverables:**
- âœ… Working Word generator
- âœ… Working Excel generator
- âœ… Test documents generated
- âœ… Ready for assignment submission

---

## Phase 9: User Interface (2-3 hours)

### âœ… Step 9.1: Implement Streamlit UI
**Duration:** 2 hours  
**Status:** âœ… COMPLETED on Oct 19, 2025

**Files Created:**
- âœ… `ui/app.py` (370+ lines)
- âœ… `ui/README.md` (comprehensive docs)
- âœ… `ui/__init__.py`
- âœ… `run_ui.py` (launcher script)
- âœ… `tests/test_ui.py` (validation tests)

**Implementation:**
Professional Streamlit web interface with comprehensive features:

1. **Main Interface**
   - Ticker input (with autocomplete hints)
   - Company name (optional)
   - Format selection (Word, Excel, or both)
   - Generate button

2. **Progress Tracking**
   - Real-time progress bar (0-100%)
   - Status text updates
   - Step-by-step notifications:
     * Initializing workflow (10%)
     * Collecting data (20-50%)
     * Generating documents (70-100%)

3. **Key Metrics Dashboard**
   - Current price & market cap
   - Beta & cost of equity
   - DDM fair value & upside/downside
   - ROE & recommendation
   - Expandable financial ratios (4 categories)

4. **Error Handling**
   - Clear error messages
   - Warning display
   - Data quality indicator

5. **Download Buttons**
   - Word report download
   - Excel workbook download
   - Proper MIME types

6. **UI Polish**
   - Custom CSS styling
   - Color-coded recommendations
   - Responsive layout
   - Professional typography
   - Sidebar with documentation

**Features:**
- âœ… Clean, modern interface
- âœ… Real-time progress indicators
- âœ… Key metrics display
- âœ… Financial ratios tabs (Liquidity, Efficiency, Solvency, Profitability)
- âœ… Error handling with clear messages
- âœ… Data quality score display
- âœ… One-click downloads
- âœ… Comprehensive sidebar documentation
- âœ… Suggested tickers
- âœ… Cross-platform compatibility

**Test Results:**
```bash
$ python tests/test_ui.py
======================================================================
TESTING UI COMPONENTS
======================================================================

ðŸ§ª Testing: UI Imports
----------------------------------------------------------------------
âœ… All UI imports successful!

ðŸ§ª Testing: UI Files
----------------------------------------------------------------------
âœ… app.py exists
âœ… README.md exists
âœ… __init__.py exists
âœ… run_ui.py exists

ðŸ§ª Testing: State Creation
----------------------------------------------------------------------
âœ… State creation successful!

ðŸ§ª Testing: Graph Creation
----------------------------------------------------------------------
âœ… Graph creation successful!

======================================================================
TEST SUMMARY
======================================================================
âœ… PASS: UI Imports
âœ… PASS: UI Files
âœ… PASS: State Creation
âœ… PASS: Graph Creation

ðŸ“Š Results: 4/4 tests passed
ðŸŽ‰ All UI tests passed!
```

**Launch Options:**
```bash
# Option 1: Using launcher script
python run_ui.py

# Option 2: Direct streamlit command
streamlit run ui/app.py
```

**Deliverables:**
- âœ… Complete Streamlit UI
- âœ… Launcher script
- âœ… Comprehensive UI documentation
- âœ… Validation tests passing
- âœ… README updated with UI instructions

---

### â³ Step 9.2: UI Testing & Polish
**Duration:** 1 hour  
**Status:** â³ In Progress

**Testing Checklist:**
- [ ] Test with multiple companies (RELIANCE, TCS, INFY, HDFCBANK, ICICIBANK)
- [ ] Verify error handling for invalid tickers
- [ ] Test with non-dividend paying companies
- [ ] Verify download functionality on different browsers
- [ ] Test on different screen sizes
- [ ] Verify LLM integration (when API key available)
- [ ] Performance testing (multiple concurrent requests)

**Polish Items:**
- [ ] Add session state persistence
- [ ] Add report history/cache
- [ ] Add company search/autocomplete
- [ ] Add comparison mode (multiple companies)
- [ ] Improve mobile responsiveness
- [ ] Add dark mode toggle

**Deliverables:**
- Polished, user-friendly UI
- Tested with 5+ companies
- Cross-browser compatibility
- Performance optimized

---

## Phase 10: Testing & Quality Assurance (2-3 hours)

### âœ… Step 10.1: Comprehensive Testing
**Duration:** 2 hours  
**Status:** â³ Pending

**Test Cases:**
1. **Happy Path:** Popular companies (AAPL, MSFT, GOOGL)
2. **Edge Cases:**
   - Recently IPO'd companies
   - Non-dividend paying stocks
   - Companies with missing data
   - International tickers
3. **Error Cases:**
   - Invalid ticker
   - Delisted companies
   - Network errors

**Testing Checklist:**
- [ ] All calculations match manual verification
- [ ] All report sections present
- [ ] Charts display correctly
- [ ] Excel formulas work
- [ ] Word document formatting correct

---

### âœ… Step 10.2: Validation Against Assignment
**Status:** â³ Pending
**Duration:** 1 hour

**Verify:**
- [ ] âœ… Company not a bank/financial institution
- [ ] âœ… 5 years of data included
- [ ] âœ… Minimum 6 ratios calculated
- [ ] âœ… Line charts for trends
- [ ] âœ… Commentary for each metric
- [ ] âœ… Beta and CAPM included
- [ ] âœ… DDM valuation performed
- [ ] âœ… Strategy analysis present
- [ ] âœ… Competitor analysis present
- [ ] âœ… Recent developments included
- [ ] âœ… Both Word + Excel files generated

---

## Phase 10: Documentation & Deployment (1-2 hours)

### ðŸ“š Step 10.1: Documentation
**Duration:** 1 hour

**Files to Create/Update:**
- [ ] README.md with usage instructions
- [ ] API documentation for tools
- [ ] Troubleshooting guide
- [ ] Sample outputs

---

### ðŸš€ Step 10.2: Deployment
**Duration:** 1 hour

**Options:**
1. **Local:** Instructions for running locally
2. **Streamlit Cloud:** Deploy UI
3. **Docker:** Containerize application (optional)

**Deliverables:**
- Deployed application
- User guide

---

## Phase 11: Cash Flow Analysis Enhancement (2-3 hours)

**Status:** â³ Pending  
**Priority:** HIGH - Assignment Requirement  
**Target:** Complete cash flow analysis as specified in assignment

### ðŸ“Š Context: Assignment Requirement

The assignment explicitly requires:
> *"Conduct ratio analysis using the latest five years' data, including financial statements and **cash flow analysis**."*

**Current State:**
- âœ… Cash flow statement collected (raw data from yfinance)
- âœ… Cash flow data used for DCF calculations (FCF, FCFE)
- âŒ **NO dedicated cash flow ratios** (Operating Cash Flow Ratio, FCF Margin, etc.)
- âŒ **NO cash flow narrative analysis** (LLM-generated section for Word report)
- âŒ **NO year-on-year cash flow trend analysis** (similar to financial ratios)

**Gap Analysis:**
When someone says "cash flow analysis", they typically expect:
1. **Cash Flow Ratios** - Measuring liquidity, quality of earnings, and financial flexibility
2. **Cash Flow Trends** - Year-over-year analysis of operating, investing, and financing activities
3. **Narrative Analysis** - Discussion of cash generation ability, sustainability, and concerns
4. **Comparison to Peers** - How the company's cash flow compares to industry norms

### âœ… Step 11.1: Cash Flow Ratio Calculator
**Duration:** 1 hour  
**Status:** â³ Pending

**Ratios to Implement (8-10 ratios):**

**Operating Cash Flow Ratios:**
1. **Operating Cash Flow Ratio** = Operating Cash Flow / Current Liabilities
   - Measures ability to pay short-term obligations from operations
   - Better than current ratio (uses cash, not accruals)

2. **Cash Flow to Sales Ratio** = Operating Cash Flow / Revenue
   - Operating cash flow margin
   - Shows quality of revenue (cash vs. accrual)

3. **Cash Flow Return on Assets** = Operating Cash Flow / Total Assets
   - Measures efficiency of cash generation from assets

**Free Cash Flow Ratios:**
4. **Free Cash Flow Margin** = Free Cash Flow / Revenue
   - FCF as % of sales
   - Key profitability metric

5. **FCF to Operating Cash Flow Ratio** = FCF / Operating Cash Flow
   - Shows % of OCF remaining after CapEx
   - High ratio = less capital intensive

**Quality of Earnings:**
6. **Cash Flow to Net Income Ratio** = Operating Cash Flow / Net Income
   - Quality of earnings check
   - Should be close to 1.0; >1.0 is excellent, <0.7 is concerning

7. **Accrual Ratio** = (Net Income - Operating Cash Flow) / Total Assets
   - High accruals may indicate aggressive accounting
   - Lower is better (less accrual-based earnings)

**Financial Flexibility:**
8. **Cash Flow Coverage Ratio** = Operating Cash Flow / Total Debt
   - Ability to pay off debt from operations
   - Higher is better

9. **Dividend Coverage (Cash)** = Free Cash Flow / Dividends Paid
   - Can the company sustain dividends from FCF?
   - >1.5 is healthy

10. **Capital Expenditure Coverage** = Operating Cash Flow / Capital Expenditure
    - How many times can CapEx be covered by OCF?
    - >2.0 is comfortable

**Implementation Details:**
- Add `CashFlowRatioCalculator` class to `tools/ratio_calculator.py` (or new file `tools/cashflow_calculator.py`)
- Similar structure to existing `RatioCalculator`
- Use existing cash flow statement data from state
- Calculate year-on-year for all available periods (4 years from yfinance)
- Add trend analysis (improving/deteriorating)

**Deliverables:**
- [ ] `tools/cashflow_calculator.py` with `CashFlowRatioCalculator` class
- [ ] 8-10 cash flow ratios implemented
- [ ] Year-on-year calculation support
- [ ] Trend analysis (similar to financial ratios)
- [ ] Unit tests for all ratios

---

### âœ… Step 11.2: Integrate Cash Flow Ratios into Workflow
**Duration:** 30 minutes  
**Status:** â³ Pending

**State Schema Updates:**
Add to `agents/state.py`:
```python
# In EquityResearchState TypedDict
cashflow_ratios: Optional[Dict[str, Dict[str, List[float]]]]
cashflow_ratios_by_year: Optional[List[Dict[str, Any]]]
cashflow_trends: Optional[Dict[str, Dict[str, Any]]]
```

**Financial Analysis Node Updates:**
Modify `agents/nodes/financial_analysis.py` to:
1. Import `CashFlowRatioCalculator`
2. Add new Step 4.5 (after regular ratios, before Beta):
   ```python
   # Step 4.5: Calculate cash flow ratios
   calculator = CashFlowRatioCalculator(cash_flow, income_statement, balance_sheet)
   cashflow_ratios_by_year = []
   for period in range(num_periods):
       period_ratios = calculator.calculate_all_ratios(period)
       cashflow_ratios_by_year.append({...})
   ```
3. Update state with cash flow ratio results
4. Update summary logging to include cash flow metrics

**Deliverables:**
- [ ] State schema updated with cash flow ratio fields
- [ ] Financial analysis node updated to calculate cash flow ratios
- [ ] Proper error handling and logging
- [ ] Integration tested with sample company

---

### âœ… Step 11.3: Cash Flow Narrative Analysis (LLM)
**Duration:** 45 minutes  
**Status:** â³ Pending

**Add New Report Section:**
Create dedicated "Cash Flow Analysis" section in Word report (between Financial Analysis and Valuation Analysis).

**LLM Prompt for Cash Flow Analysis:**
```python
CASHFLOW_ANALYSIS_PROMPT = """Write a comprehensive cash flow analysis section (3-4 paragraphs).

Company: {company_name}

YEAR-ON-YEAR OPERATING CASH FLOW RATIOS:
{operating_cf_ratios_yoy}

YEAR-ON-YEAR FREE CASH FLOW RATIOS:
{free_cf_ratios_yoy}

YEAR-ON-YEAR QUALITY OF EARNINGS RATIOS:
{quality_ratios_yoy}

YEAR-ON-YEAR FINANCIAL FLEXIBILITY RATIOS:
{flexibility_ratios_yoy}

RAW CASH FLOW DATA (for context):
- Latest Operating Cash Flow: {latest_ocf}
- Latest Free Cash Flow: {latest_fcf}
- Latest Capital Expenditure: {latest_capex}
- Operating CF 3-year trend: {ocf_trend}

Analyze:
1. **Operating Cash Flow Strength** - Assess the company's ability to generate cash from core operations
   - Compare OCF to revenue and net income
   - Identify trends (improving/deteriorating)
   - Evaluate OCF sustainability

2. **Free Cash Flow Generation** - Evaluate cash available after necessary investments
   - FCF trends and margins
   - Capital intensity (CapEx as % of OCF)
   - Ability to fund growth, dividends, and debt repayment

3. **Quality of Earnings** - Assess earnings quality using cash flow metrics
   - Compare OCF to Net Income (should be close)
   - Check accrual levels (high accruals = potential red flag)
   - Identify any aggressive accounting concerns

4. **Financial Flexibility** - Evaluate the company's financial cushion
   - Ability to cover debt obligations from cash flow
   - Dividend sustainability from FCF
   - Capacity for future investments

5. **Overall Cash Flow Health** - Provide a holistic assessment
   - Compare to industry norms
   - Highlight strengths and concerns
   - Investment implications

IMPORTANT: Focus on cash flow trends and what they mean for the business. Explain whether cash flow is strengthening or weakening over time."""
```

**Report Writing Node Updates:**
Modify `agents/nodes/report_writing.py` to:
1. Add `CASHFLOW_ANALYSIS_PROMPT` (new prompt)
2. Add helper function `format_cashflow_ratios_by_year` (similar to `format_ratios_by_year`)
3. Add new section generation step (Step 3.5: Cash Flow Analysis)
4. Update state field: `cashflow_analysis_text`
5. Update section order in summary

**Word Generator Updates:**
Modify `generators/word_generator.py` to:
1. Add new section "4. Cash Flow Analysis" (after Financial Analysis, before Valuation)
2. Update section numbering accordingly
3. Apply professional formatting

**State Schema Updates:**
Add to `agents/state.py`:
```python
cashflow_analysis_text: Optional[str]  # In REPORT WRITING NODE OUTPUT section
```

**Deliverables:**
- [ ] New LLM prompt for cash flow analysis
- [ ] Helper functions for formatting cash flow data
- [ ] Report writing node updated with new section
- [ ] Word generator updated with new section
- [ ] State schema updated
- [ ] Tested with sample company

---

### âœ… Step 11.4: Enhanced Excel Cash Flow Sheet
**Duration:** 45 minutes  
**Status:** â³ Pending

**Current Excel Cash Flow Sheet:**
- Shows raw cash flow statement (Operating, Investing, Financing activities)
- Minimal formatting
- No ratios or analysis

**Enhancements to Implement:**

**1. Add Cash Flow Ratios Section:**
- Similar to Financial Ratios sheet
- Categories:
  - Operating Cash Flow Ratios
  - Free Cash Flow Ratios
  - Quality of Earnings
  - Financial Flexibility
- Year-on-year comparison
- Trend indicators (â†‘â†“â†’)

**2. Add Cash Flow Summary Section:**
- Key metrics table:
  - Operating Cash Flow (by year)
  - Free Cash Flow (by year)
  - Capital Expenditure (by year)
  - FCF Margin (by year)
  - OCF/Net Income Ratio (by year)

**3. Add Cash Flow Charts:**
- Line chart: Operating Cash Flow trend
- Line chart: Free Cash Flow trend
- Bar chart: Cash Flow breakdown (Operating, Investing, Financing)

**4. Add Calculated Fields:**
- Free Cash Flow = Operating CF - CapEx
- FCF Margin = FCF / Revenue
- OCF Margin = OCF / Revenue

**Excel Generator Updates:**
Modify `generators/excel_generator.py`:
1. Update `_add_cashflow_sheet` method
2. Add ratio table (similar to Financial Ratios sheet)
3. Add summary metrics table
4. Add Excel charts for visualization
5. Improve formatting (professional styling)

**Deliverables:**
- [ ] Enhanced Excel Cash Flow sheet with ratios
- [ ] Summary metrics table
- [ ] Year-on-year comparison
- [ ] Professional formatting and charts
- [ ] Tested with sample company

---

### âœ… Step 11.5: Testing & Validation
**Duration:** 30 minutes  
**Status:** â³ Pending

**Test Cases:**
1. **Cash Flow Positive Company** (e.g., TCS, RELIANCE)
   - Verify all ratios calculate correctly
   - Check LLM analysis makes sense
   - Validate Excel formatting

2. **Cash Flow Negative Company** (high CapEx, growth phase)
   - Verify negative FCF handled correctly
   - Check LLM explains the situation appropriately

3. **No Dividend Company**
   - Ensure dividend coverage ratio returns N/A gracefully

**Validation Checklist:**
- [ ] All cash flow ratios calculate correctly
- [ ] Year-on-year trends show properly
- [ ] LLM analysis is coherent and insightful
- [ ] Excel sheet displays all data correctly
- [ ] No errors or exceptions
- [ ] Manual spot-check of 2-3 companies

**Deliverables:**
- [ ] All tests passing
- [ ] Manual verification completed
- [ ] Edge cases handled gracefully

---

### ðŸ“Š Phase 11 Summary

**Total Duration:** 2-3 hours  
**Impact:** HIGH - Completes assignment requirement for "cash flow analysis"

**Files to Modify/Create:**
1. `tools/cashflow_calculator.py` (NEW) - 8-10 cash flow ratios
2. `agents/state.py` (MODIFY) - Add cash flow ratio fields
3. `agents/nodes/financial_analysis.py` (MODIFY) - Integrate cash flow ratio calculation
4. `agents/nodes/report_writing.py` (MODIFY) - Add LLM cash flow analysis section
5. `generators/word_generator.py` (MODIFY) - Add cash flow section to report
6. `generators/excel_generator.py` (MODIFY) - Enhance cash flow sheet
7. `tests/test_cashflow.py` (NEW) - Unit tests for cash flow calculator

**Expected Output:**
- âœ… Word Report: New "Cash Flow Analysis" section (3-4 paragraphs, LLM-generated)
- âœ… Excel Workbook: Enhanced Cash Flow sheet with ratios, trends, and charts
- âœ… Complete cash flow analysis satisfying assignment requirement
- âœ… Professional-grade analysis (not just raw data dump)

**Success Criteria:**
- [ ] 8-10 cash flow ratios implemented and calculating correctly
- [ ] Year-on-year cash flow trends available
- [ ] LLM-generated cash flow narrative (3-4 paragraphs)
- [ ] Enhanced Excel cash flow sheet with ratios and charts
- [ ] Assignment requirement fully satisfied
- [ ] Tested with 3+ companies

---

## Phase 12: Bloomberg Terminal Data Integration (2.5-3 hours)

**Status:** ðŸ”„ Parser Complete, Integration Pending  
**Priority:** MEDIUM - Data Quality Enhancement  
**Target:** Enable Bloomberg Terminal data as primary source for enhanced accuracy

### ðŸ“Š Context: Why Bloomberg Integration?

**Bloomberg Terminal Advantages:**
- ðŸ“ˆ **10 years** of historical data (vs. 4 years from yfinance)
- âœ… **Professional-grade** adjustments and standardization
- ðŸŽ¯ **97 balance sheet fields** (vs. 30-50 from yfinance)
- ðŸ“Š **Pre-calculated ratios** (P/E, EV/EBITDA, Dividend Payout, etc.)
- ðŸ”® **Forward estimates** (analyst projections for future years)
- âš¡ **Real-time** data when exported (vs. quarterly lag in free sources)
- ðŸ’¹ **Monthly stock prices** with proper adjustments

**Current Implementation Status:**
- âœ… Bloomberg parser module complete (`tools/bloomberg_parser.py`)
- âœ… Can parse all 5 sheets: Income Statement, Balance Sheet, Cash Flow, Stock Prices, Financial Metrics
- âœ… Tested with real Bloomberg file (Tata Steel Ltd)
- âœ… Documentation complete (`docs/BLOOMBERG_DATA_INTEGRATION.md`)
- âŒ **NOT integrated** into main workflow yet
- âŒ **NOT connected** to data collection node
- âŒ **NO field mapping** (Bloomberg â†’ yfinance schema)
- âŒ **NO UI support** for file upload

---

### âœ… Step 12.1: State Schema Updates
**Duration:** 15 minutes  
**Status:** â³ Pending

**Add to `agents/state.py`:**

```python
# ==================== DATA SOURCE TRACKING ====================
data_source: Literal['yfinance', 'bloomberg', 'hybrid']
"""Data source used for this report: yfinance (free), bloomberg (terminal export), or hybrid (both)"""

bloomberg_file_path: Optional[str]
"""Path to Bloomberg Excel file if used"""

bloomberg_raw_data: Optional[Dict[str, pd.DataFrame]]
"""Raw parsed Bloomberg data:
- income_statement: DataFrame (75 fields Ã— 10 periods)
- balance_sheet: DataFrame (97 fields Ã— 10 periods)  
- cash_flow: DataFrame (56 fields Ã— 10 periods)
- stock_prices: DataFrame (time series, Date index, Close column)
- financial_metrics: DataFrame (pre-calculated ratios)
"""

data_source_metadata: Optional[Dict[str, Any]]
"""Metadata about data sources:
- bloomberg_periods: int (number of historical periods from Bloomberg)
- yfinance_periods: int (number of periods from yfinance)
- hybrid_mode: bool (using both sources)
- primary_source: str (which source takes precedence)
- fallback_fields: List[str] (fields that fell back to yfinance)
"""
```

**Deliverables:**
- [ ] Add 4 new fields to `EquityResearchState` TypedDict
- [ ] Add comprehensive documentation for each field
- [ ] Update state schema diagram (if exists)

---

### âœ… Step 12.2: Bloomberg Field Mapper
**Duration:** 1 hour  
**Status:** â³ Pending

**Create `tools/bloomberg_mapper.py`:**

**Purpose:** Map Bloomberg field names â†’ yfinance-compatible field names

**Bloomberg â†’ yfinance Field Mapping Examples:**

```python
# Income Statement Mappings
INCOME_STATEMENT_MAP = {
    # Bloomberg Field â†’ yfinance Field
    'Revenue': 'Total Revenue',
    'Cost of Goods Sold': 'Cost Of Revenue',
    'Gross Profit': 'Gross Profit',
    'Operating Income': 'Operating Income',
    'EBIT': 'EBIT',
    'EBITDA': 'EBITDA',
    'Pretax Income': 'Pretax Income',
    'Net Income': 'Net Income',
    'Diluted EPS': 'Diluted EPS',
    # ... more mappings
}

# Balance Sheet Mappings
BALANCE_SHEET_MAP = {
    'Total Assets': 'Total Assets',
    'Cash & Cash Equivalents': 'Cash And Cash Equivalents',
    'Accounts & Notes Receiv': 'Accounts Receivable',
    'Inventories': 'Inventory',
    'Total Current Assets': 'Current Assets',
    'PP&E': 'Net PPE',
    'Total Liabilities': 'Total Liabilities Net Minority Interest',
    'Current Liabilities': 'Current Liabilities',
    'Total Debt': 'Total Debt',
    'Total Equity': 'Stockholders Equity',
    # ... more mappings
}

# Cash Flow Mappings
CASHFLOW_MAP = {
    'Cash from Operating Activities': 'Operating Cash Flow',
    'Cash from Investing Activities': 'Investing Cash Flow',
    'Cash from Financing Activities': 'Financing Cash Flow',
    'Capital Expenditure': 'Capital Expenditure',
    'Free Cash Flow': 'Free Cash Flow',
    # ... more mappings
}
```

**Key Functions:**

```python
def map_bloomberg_to_yfinance(
    bloomberg_df: pd.DataFrame,
    statement_type: Literal['income', 'balance', 'cashflow']
) -> pd.DataFrame:
    """
    Map Bloomberg field names to yfinance-compatible names.
    
    Args:
        bloomberg_df: Raw DataFrame from Bloomberg parser
        statement_type: Type of financial statement
    
    Returns:
        DataFrame with yfinance-compatible field names (index)
    """
    pass

def merge_bloomberg_yfinance(
    bloomberg_df: pd.DataFrame,
    yfinance_df: pd.DataFrame,
    primary: Literal['bloomberg', 'yfinance'] = 'bloomberg'
) -> Tuple[pd.DataFrame, List[str]]:
    """
    Merge Bloomberg and yfinance data, with primary source taking precedence.
    
    Args:
        bloomberg_df: Mapped Bloomberg DataFrame
        yfinance_df: Original yfinance DataFrame
        primary: Which source takes precedence for overlapping fields
    
    Returns:
        (merged_df, fallback_fields) - Merged DataFrame and list of fields that used fallback
    """
    pass

def validate_field_mapping(
    bloomberg_df: pd.DataFrame,
    expected_fields: List[str]
) -> Tuple[bool, List[str], List[str]]:
    """
    Validate that critical fields are present after mapping.
    
    Returns:
        (is_valid, missing_fields, extra_fields)
    """
    pass
```

**Implementation Details:**
- Start with **60-80 core field mappings** (most commonly used in ratio calculations)
- Unmapped Bloomberg fields â†’ keep with original names (may be useful)
- Log unmapped fields for future enhancement
- Handle cases where Bloomberg has richer granularity (e.g., multiple revenue types)
- Add fuzzy matching for similar field names

**Deliverables:**
- [ ] `tools/bloomberg_mapper.py` with `BloombergFieldMapper` class
- [ ] 60-80 field mappings for Income Statement, Balance Sheet, Cash Flow
- [ ] `map_bloomberg_to_yfinance()` function
- [ ] `merge_bloomberg_yfinance()` function for hybrid mode
- [ ] `validate_field_mapping()` function
- [ ] Unit tests with sample Bloomberg and yfinance DataFrames
- [ ] Documentation of mapping decisions

---

### âœ… Step 12.3: Data Collection Node Integration
**Duration:** 45 minutes  
**Status:** â³ Pending

**Modify `agents/nodes/data_collection.py`:**

**New Logic Flow:**

```python
def collect_data_node(state: EquityResearchState) -> Dict[str, Any]:
    """Enhanced with Bloomberg support."""
    
    ticker = state['ticker']
    updates = {...}
    
    # ==================== STEP 0: Check for Bloomberg File ====================
    logger.info("ðŸ” Step 0: Checking for Bloomberg Terminal data...")
    
    bloomberg_file = None
    
    # Priority 1: Check if file path provided in state
    if state.get('bloomberg_file_path'):
        bloomberg_file = state['bloomberg_file_path']
        logger.info(f"   Using provided Bloomberg file: {bloomberg_file}")
    
    # Priority 2: Auto-detect in data/bloomberg/ directory
    else:
        from tools.bloomberg_parser import detect_bloomberg_file
        bloomberg_file = detect_bloomberg_file('data/bloomberg/', ticker)
        if bloomberg_file:
            logger.info(f"   Auto-detected Bloomberg file: {bloomberg_file}")
    
    # Priority 3: Check Downloads folder
    if not bloomberg_file:
        bloomberg_file = detect_bloomberg_file('~/Downloads/', ticker)
        if bloomberg_file:
            logger.info(f"   Found Bloomberg file in Downloads: {bloomberg_file}")
    
    # ==================== BLOOMBERG DATA PARSING ====================
    if bloomberg_file:
        try:
            from tools.bloomberg_parser import parse_bloomberg_file
            from tools.bloomberg_mapper import map_bloomberg_to_yfinance
            
            logger.info(f"ðŸ“Š Parsing Bloomberg file...")
            bloomberg_data = parse_bloomberg_file(bloomberg_file)
            
            # Extract and map financial statements
            mapped_statements = {}
            for stmt_type in ['income_statement', 'balance_sheet', 'cash_flow']:
                if stmt_type in bloomberg_data['data']:
                    mapped_df = map_bloomberg_to_yfinance(
                        bloomberg_data['data'][stmt_type],
                        stmt_type.split('_')[0]  # 'income', 'balance', 'cashflow'
                    )
                    mapped_statements[stmt_type] = mapped_df
            
            updates['financial_statements'] = mapped_statements
            updates['data_source'] = 'bloomberg'
            updates['bloomberg_file_path'] = bloomberg_file
            updates['bloomberg_raw_data'] = bloomberg_data['data']
            
            # Use Bloomberg stock prices if available
            if 'stock_prices' in bloomberg_data['data']:
                updates['stock_prices'] = bloomberg_data['data']['stock_prices']
                logger.success("âœ… Using Bloomberg stock prices")
            else:
                # Fallback to yfinance for prices
                updates['stock_prices'] = fetch_stock_prices(ticker, exchange="NSE")
                updates['data_source'] = 'hybrid'
                logger.info("   Fallback: Using yfinance for stock prices")
            
            # Get company info from yfinance (Bloomberg doesn't have this)
            updates['company_info'] = fetch_company_info(ticker, exchange="NSE")
            updates['data_source'] = 'hybrid'
            
            logger.success(f"âœ… Bloomberg data loaded: {len(mapped_statements)} statements")
            
        except Exception as e:
            logger.error(f"âŒ Bloomberg parsing failed: {e}")
            logger.info("   Falling back to yfinance...")
            bloomberg_file = None  # Fall through to yfinance
    
    # ==================== YFINANCE FALLBACK ====================
    if not bloomberg_file:
        logger.info("ðŸ“Š Using yfinance data source...")
        # Original yfinance logic (current implementation)
        financial_data = fetch_all_company_data(ticker, exchange="NSE", years=6)
        updates['financial_statements'] = {...}
        updates['data_source'] = 'yfinance'
        # ... rest of current logic ...
    
    # ==================== DATA SOURCE METADATA ====================
    updates['data_source_metadata'] = {
        'primary_source': updates['data_source'],
        'bloomberg_periods': len(updates['financial_statements']['income_statement'].columns) if updates['data_source'] in ['bloomberg', 'hybrid'] else 0,
        'yfinance_periods': len(updates['financial_statements']['income_statement'].columns) if updates['data_source'] == 'yfinance' else 0,
        'hybrid_mode': updates['data_source'] == 'hybrid',
        'timestamp': datetime.now().isoformat()
    }
    
    return updates
```

**Deliverables:**
- [ ] Modify `collect_data_node()` in `agents/nodes/data_collection.py`
- [ ] Add Bloomberg file detection (3 priorities: provided path, data/bloomberg/, Downloads)
- [ ] Add Bloomberg parsing and field mapping
- [ ] Add fallback logic to yfinance
- [ ] Track data source in state
- [ ] Proper error handling and logging
- [ ] Test with both Bloomberg and yfinance data sources

---

### âœ… Step 12.4: UI Enhancements
**Duration:** 30 minutes  
**Status:** â³ Pending

**Modify `run_ui.py`:**

**Add File Upload Widget:**

```python
# In the sidebar, after ticker input
st.sidebar.markdown("---")
st.sidebar.markdown("### ðŸ“Š Data Source")

data_source_option = st.sidebar.radio(
    "Choose data source:",
    options=["Auto-detect", "yfinance (Free)", "Bloomberg Terminal (Upload)"],
    index=0,
    help="Auto-detect will check for Bloomberg files first, then fallback to yfinance"
)

bloomberg_file_path = None

if data_source_option == "Bloomberg Terminal (Upload)":
    uploaded_file = st.sidebar.file_uploader(
        "Upload Bloomberg Excel Export",
        type=['xlsx', 'xls'],
        help="Export from Bloomberg Terminal: FS, DVD, PRICE (all sheets)"
    )
    
    if uploaded_file:
        # Save uploaded file to temp location
        import tempfile
        with tempfile.NamedTemporaryFile(delete=False, suffix='.xlsx') as tmp_file:
            tmp_file.write(uploaded_file.getvalue())
            bloomberg_file_path = tmp_file.name
        
        st.sidebar.success(f"âœ… Bloomberg file uploaded: {uploaded_file.name}")

elif data_source_option == "Auto-detect":
    # Check if Bloomberg files exist
    from tools.bloomberg_parser import detect_bloomberg_file
    detected_file = detect_bloomberg_file('data/bloomberg/', ticker) or \
                    detect_bloomberg_file('~/Downloads/', ticker)
    
    if detected_file:
        st.sidebar.info(f"ðŸ” Found Bloomberg file: {Path(detected_file).name}")
        bloomberg_file_path = detected_file
    else:
        st.sidebar.info("ðŸ” No Bloomberg file found, will use yfinance")

# Pass bloomberg_file_path to workflow
initial_state = {
    'ticker': ticker,
    'company_name': company_name or ticker,
    'bloomberg_file_path': bloomberg_file_path
}
```

**Add Data Source Badge in Results:**

```python
# After report generation, show data source
if 'data_source' in result:
    source = result['data_source']
    if source == 'bloomberg':
        st.success("ðŸ“Š Data Source: Bloomberg Terminal (10 years of data)")
    elif source == 'hybrid':
        st.info("ðŸ“Š Data Source: Hybrid (Bloomberg + yfinance)")
    else:
        st.info("ðŸ“Š Data Source: yfinance (Free)")
    
    # Show metadata
    if 'data_source_metadata' in result:
        metadata = result['data_source_metadata']
        with st.expander("ðŸ” Data Source Details"):
            st.json(metadata)
```

**Deliverables:**
- [ ] Add file upload widget in sidebar
- [ ] Add data source selection radio buttons
- [ ] Add auto-detection logic with visual feedback
- [ ] Pass `bloomberg_file_path` to workflow
- [ ] Display data source badge in results
- [ ] Add data source metadata expander
- [ ] Handle file cleanup (temp files)

---

### âœ… Step 12.5: Report Generation Updates
**Duration:** 30 minutes  
**Status:** â³ Pending

**Update Report Writing Node:**

**Modify `agents/nodes/report_writing.py`:**

```python
# In company_overview_prompt, add data source context
COMPANY_OVERVIEW_PROMPT = """...

DATA SOURCE:
{data_source_context}

...
"""

def format_data_source_context(state: EquityResearchState) -> str:
    """Format data source information for LLM context."""
    source = state.get('data_source', 'yfinance')
    metadata = state.get('data_source_metadata', {})
    
    if source == 'bloomberg':
        periods = metadata.get('bloomberg_periods', 0)
        return f"Analysis based on Bloomberg Terminal data ({periods} years of historical data). Professional-grade financial data with comprehensive field coverage."
    elif source == 'hybrid':
        return f"Analysis based on hybrid data: Bloomberg Terminal for financial statements, yfinance for real-time pricing and company information."
    else:
        periods = metadata.get('yfinance_periods', 0)
        return f"Analysis based on publicly available financial data from yfinance ({periods} years of historical data)."
```

**Update Word Generator:**

**Modify `generators/word_generator.py`:**

```python
def _add_appendix(self, doc, state):
    """Add appendix with data sources and disclaimers."""
    # ... existing code ...
    
    # Add data source disclosure
    doc.add_heading("Data Sources", level=2)
    
    source = state.get('data_source', 'yfinance')
    metadata = state.get('data_source_metadata', {})
    
    if source == 'bloomberg':
        doc.add_paragraph(
            f"Financial data sourced from Bloomberg Terminal. "
            f"Historical data: {metadata.get('bloomberg_periods', 0)} years. "
            f"Data extraction date: {metadata.get('timestamp', 'N/A')}."
        )
    elif source == 'hybrid':
        doc.add_paragraph(
            "This report uses a hybrid data approach: Bloomberg Terminal for comprehensive "
            "financial statement data, supplemented with yfinance for real-time market data "
            "and company information."
        )
    else:
        doc.add_paragraph(
            f"Financial data sourced from Yahoo Finance (yfinance). "
            f"Historical data: {metadata.get('yfinance_periods', 0)} years."
        )
```

**Update Excel Generator:**

**Modify `generators/excel_generator.py`:**

```python
def _add_summary_sheet(self, wb, state):
    """Add summary sheet with data source information."""
    ws = wb.create_sheet('Summary', 0)
    
    # ... existing summary content ...
    
    # Add data source section
    row = 15  # After other summary info
    ws[f'A{row}'] = 'Data Source:'
    ws[f'A{row}'].font = Font(bold=True)
    
    source = state.get('data_source', 'yfinance')
    metadata = state.get('data_source_metadata', {})
    
    if source == 'bloomberg':
        ws[f'B{row}'] = f"Bloomberg Terminal ({metadata.get('bloomberg_periods', 0)} years)"
        ws[f'B{row}'].fill = PatternFill(start_color='90EE90', fill_type='solid')  # Light green
    elif source == 'hybrid':
        ws[f'B{row}'] = "Hybrid (Bloomberg + yfinance)"
        ws[f'B{row}'].fill = PatternFill(start_color='ADD8E6', fill_type='solid')  # Light blue
    else:
        ws[f'B{row}'] = f"yfinance ({metadata.get('yfinance_periods', 0)} years)"
```

**Deliverables:**
- [ ] Add data source context to LLM prompts
- [ ] Update Word report appendix with data source disclosure
- [ ] Update Excel summary sheet with data source badge
- [ ] Add data source metadata to both reports
- [ ] Professional formatting for data source information

---

### âœ… Step 12.6: Testing & Validation
**Duration:** 30 minutes  
**Status:** â³ Pending

**Test Scenarios:**

**1. Bloomberg-Only Mode:**
- [ ] Use Tata Steel Ltd Bloomberg file
- [ ] Verify all 10 years of data loaded
- [ ] Check ratio calculations (compare to pre-calculated Bloomberg ratios)
- [ ] Validate DCF uses correct historical data
- [ ] Confirm Word report mentions Bloomberg source
- [ ] Confirm Excel shows Bloomberg badge

**2. yfinance-Only Mode:**
- [ ] Generate report for company without Bloomberg file
- [ ] Verify graceful fallback
- [ ] Check that all existing functionality still works
- [ ] Confirm 4-5 years of data loaded

**3. Hybrid Mode:**
- [ ] Bloomberg file with missing stock prices
- [ ] Verify fallback to yfinance for prices
- [ ] Confirm hybrid badge displayed
- [ ] Check metadata shows both sources

**4. Error Handling:**
- [ ] Upload corrupted Bloomberg file
- [ ] Upload non-Bloomberg Excel file
- [ ] Verify graceful error messages
- [ ] Confirm fallback to yfinance works

**5. Field Mapping Validation:**
- [ ] Compare ratios: Bloomberg data vs. yfinance data
- [ ] Spot-check 5-10 key fields (Revenue, Net Income, Total Assets, etc.)
- [ ] Verify no critical fields missing after mapping

**Validation Checklist:**
- [ ] Bloomberg parser integrates successfully
- [ ] Field mapping works correctly
- [ ] No errors with Bloomberg data
- [ ] No errors with yfinance fallback
- [ ] Data source tracked properly in state
- [ ] UI shows correct data source badge
- [ ] Reports include data source disclosure
- [ ] Manual validation with 2-3 companies

**Deliverables:**
- [ ] All test scenarios passing
- [ ] Field mapping validated (spot-check)
- [ ] Edge cases handled gracefully
- [ ] Documentation updated with test results

---

### ðŸ“Š Phase 12 Summary

**Total Duration:** 2.5-3 hours  
**Impact:** MEDIUM-HIGH - Significantly improves data quality and historical depth

**Files to Modify/Create:**
1. `agents/state.py` (MODIFY) - Add 4 new fields for Bloomberg tracking
2. `tools/bloomberg_mapper.py` (NEW) - Field mapping (Bloomberg â†’ yfinance schema)
3. `agents/nodes/data_collection.py` (MODIFY) - Bloomberg integration with fallback
4. `run_ui.py` (MODIFY) - File upload widget and auto-detection
5. `agents/nodes/report_writing.py` (MODIFY) - Data source context for LLM
6. `generators/word_generator.py` (MODIFY) - Data source disclosure in appendix
7. `generators/excel_generator.py` (MODIFY) - Data source badge in summary
8. `tests/test_bloomberg_integration.py` (NEW) - Integration tests
9. `data/bloomberg/` (NEW DIRECTORY) - For storing Bloomberg files

**Expected Output:**
- âœ… Bloomberg Terminal data support (10 years vs. 4 years)
- âœ… Automatic fallback to yfinance (zero disruption to existing workflow)
- âœ… Hybrid mode (Bloomberg + yfinance)
- âœ… UI file upload for Bloomberg Excel exports
- âœ… Data source tracking and disclosure in reports
- âœ… Professional data source badges (Word + Excel)
- âœ… 60-80 field mappings (Bloomberg â†’ yfinance schema)

**Success Criteria:**
- [ ] Bloomberg data loads and maps correctly
- [ ] All existing functionality works with Bloomberg data
- [ ] yfinance fallback works seamlessly
- [ ] UI supports file upload and auto-detection
- [ ] Reports disclose data source professionally
- [ ] Field mapping covers 80%+ of critical fields
- [ ] Tested with 3+ companies (Bloomberg + yfinance)

**Benefits:**
- ðŸ“ˆ **2.5x more historical data** (10 years vs. 4 years)
- âœ… **Professional-grade data** (Bloomberg adjustments)
- ðŸŽ¯ **Richer analysis** (more fields, pre-calculated ratios)
- ðŸ”® **Forward estimates** (analyst projections available)
- ðŸ’¼ **Assignment credibility** (Bloomberg Terminal usage demonstrates access to professional tools)

**Next Steps After Phase 12:**
- Optional: Add Bloomberg dividend data parsing
- Optional: Use Bloomberg's pre-calculated ratios for validation
- Optional: Integrate forward estimates into valuation models
- Optional: Add Bloomberg company profiles (sector, industry, description)

---

## Milestone Checklist

### Milestone 1: Data Pipeline âœ…
- [ ] All data tools implemented
- [ ] Agent 1 fully functional
- [ ] CSV outputs validated

### Milestone 2: Analysis Engine âœ…
- [ ] All calculation tools implemented
- [ ] Agent 2 fully functional
- [ ] Excel outputs validated

### Milestone 3: Report Generator âœ…
- [ ] All synthesis tools implemented
- [ ] Agent 3 fully functional
- [ ] Word outputs validated

### Milestone 4: System Integration âœ…
- [ ] LangGraph orchestrator working
- [ ] End-to-end flow tested
- [ ] Error handling verified

### Milestone 5: User Interface âœ…
- [ ] Streamlit UI complete
- [ ] User-friendly and intuitive
- [ ] Download functionality working

### Milestone 6: Production Ready âœ…
- [ ] Comprehensive testing complete
- [ ] Documentation complete
- [ ] Deployed and accessible

---

## Risk Mitigation

### Potential Risks & Solutions

**Risk 1: API Rate Limits**
- Solution: Implement caching, use multiple data sources

**Risk 2: LLM Token Limits**
- Solution: Chunk large documents, summarize intermediates

**Risk 3: Missing Financial Data**
- Solution: Graceful degradation, clear warnings

**Risk 4: Calculation Errors**
- Solution: Extensive unit tests, validation against known values

**Risk 5: Time Constraints**
- Solution: Prioritize MVP features, defer nice-to-haves

---

## Development Principles

1. **Incremental Development**: Build and test one component at a time
2. **Test Early**: Write tests alongside code
3. **Iterate**: Start simple, add complexity
4. **Document**: Comment code, update docs
5. **Version Control**: Commit frequently with clear messages

---

## Success Criteria

### MVP (Minimum Viable Product)
âœ… Generates complete report for 1 company
âœ… All calculations correct
âœ… Professional-looking output
âœ… Works for 80% of S&P 500 companies

### Full Success
âœ… Works for 95%+ of public companies
âœ… <5 minute generation time
âœ… Beautiful UI
âœ… Comprehensive error handling
âœ… Ready for real-world use

---

## Next Steps

**Immediate:**
1. Review this roadmap
2. Set up development environment
3. Begin Phase 1

**After MVP:**
1. Gather feedback
2. Iterate on quality
3. Add enhancements

---

## Questions Before Starting?

- âœ… **LLM**: Ollama installed? (Recommended) - OR using Groq/Gemini free tier?
- âœ… **Data Source**: yfinance is perfect for Indian markets (NSE/BSE) - No keys needed!
- âœ… **Deployment**: Local deployment (Streamlit) is best for free setup
- âœ… **Test Companies**: Which Indian companies to test with?
  - Suggested: RELIANCE.NS, TCS.NS, INFY.NS, HDFCBANK.NS

**Ready to begin? Let's start with Phase 1! ðŸš€**

**Note**: Everything is 100% free - No paid APIs or subscriptions required!

